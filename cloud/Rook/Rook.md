#

## Rook

> [rook](https://github.com/rook/rook)
> [rook on k8s with ceph](https://github.com/rook/rook)
> ![rook with k8s](http://www.yangguanjun.com/images/rook-architecture.png)

Rook with Ceph is at Stable status where others are Alpha or Beta

> deploy ceph cluster with rook
>
> ![architecture](http://www.yangguanjun.com/images/kubernetes.png)
>
> after deploy ceph cluster with rook, it provides Volume Claim to App in k8s
>
> three kinds of Volume Claim services (from Ceph):
>
> - Volume: no extra components
> - FileSystem: deploy with MDS
> - Object: deploy with RGW

## Rook operator

- the component where Rook interact with K8s
- only one inside the whole Rook cluster

## Rook Agent

- interact with Rook operator, execute commands
- run on each node in the cluster as well as Rook operator pod (every k8s node).
- different Agent for different storage systems

## Get_started

> [example yaml](https://github.com/rook/rook/tree/release-1.0/cluster/examples/kubernetes/ceph)

- start minikube
  - `minikube start`
- deploy rook operator
  - `kubectl create -f common.yaml`
  - `kubectl create -f operator.yaml`
  - verify rook-ceph-operator, rook-ceph-agent and rook-discover pods are in `Running` status
    - `kubectl -n rook-ceph get pod`
- create rook ceph cluster
  - change `dataDirHostPath` to `/data/rook` in `cluster.yaml`
  - `kubectl create -f cluster.yaml`
  - `kubectl -n rook-ceph get pod -o wide`

    ```bash
    NAME                                   READY   STATUS      RESTARTS   AGE   IP            NODE       NOMINATED NODE   READINESS GATES
    rook-ceph-agent-2m8pg                  1/1     Running     0          18m   10.0.2.15     minikube   <none>           <none>
    rook-ceph-mgr-a-59c767b6f6-vszwm       1/1     Running     0          14m   172.17.0.10   minikube   <none>           <none>
    rook-ceph-mon-a-76894554fc-ftbp4       1/1     Running     0          15m   172.17.0.7    minikube   <none>           <none>
    rook-ceph-mon-b-7fcb8b77f9-jfnft       1/1     Running     0          15m   172.17.0.8    minikube   <none>           <none>
    rook-ceph-mon-c-75b6987849-7x2t4       1/1     Running     0          14m   172.17.0.9    minikube   <none>           <none>
    rook-ceph-operator-7bbb59d7bd-jsxz6    1/1     Running     0          19m   172.17.0.5    minikube   <none>           <none>
    rook-ceph-osd-prepare-minikube-g2lhj   0/2     Completed   1          14m   172.17.0.11   minikube   <none>           <none>
    rook-discover-2c6gt                    1/1     Running     0          18m   172.17.0.6    minikube   <none>           <none>
    ```

  - `kubectl -n rook-ceph get deployment`

    ```bash
    NAME                 READY   UP-TO-DATE   AVAILABLE   AGE
    rook-ceph-mgr-a      1/1     1            1           16m
    rook-ceph-mon-a      1/1     1            1           17m
    rook-ceph-mon-b      1/1     1            1           17m
    rook-ceph-mon-c      1/1     1            1           16m
    rook-ceph-operator   1/1     1            1           21m
    ```

  - enter in ceph-mon container to see the ceph.conf `docker exec -it b3aa2496c62e bash`
    - `find . -name ceph.conf`
    - `cat ./etc/ceph/ceph.conf`

  - enter in ceph-mgr container to see the ceph.conf `docker exec -it b3aa2496c62e bash`
    - `cat ./etc/ceph/ceph.conf`

  - ceph cluster config is generated by `pkg/daemon/ceph/config/config.go`

- check operator pod log
  - find the pod `kubectl -n rook-ceph get pods -o wide | grep operator`
  - check log `kubectl -n rook-ceph log rook-ceph-operator-7bbb59d7bd-jsxz6 | less`

- check component log
  - `kubectl -n rook-ceph log rook-ceph-mon-a-76894554fc-ftbp4`

- ceph-toolbox:
  - > https://rook.io/docs/rook/v1.0/ceph-toolbox.html
  - deploy: `kubectl create -f toolbox.yaml`
  - check: `kubectl -n rook-ceph get pods -o wide | grep ceph-tools`
  - enter this pod and try Ceph CLI command: `kubectl -n rook-ceph exec -it rook-ceph-tools-7855f6666-8mdnh bash`
  - `ceph status`

    ```bash
    [root@minikube /]# ceph status
    cluster:
        id:     cc5f7923-4566-4c88-81ab-70efe6d5a840
        health: HEALTH_OK

    services:
        mon: 3 daemons, quorum a,b,c (age 83m)
        mgr: a(active, since 82m)
        osd: 0 osds: 0 up, 0 in

    data:
        pools:   0 pools, 0 pgs
        objects: 0 objects, 0 B
        usage:   0 B used, 0 B / 0 B avail
        pgs:
    ```

  - `cat /etc/ceph/ceph.conf`

    ```bash
    [root@minikube /]# cat /etc/ceph/ceph.conf
    [global]
    mon_host = 10.111.151.180:6789,10.98.115.176:6789,10.109.88.55:6789

    [client.admin]
    keyring = /etc/ceph/keyring
    ```

  - `cat /etc/ceph/ceph.conf`

    ```bash
    [root@minikube /]# cat /etc/ceph/rbdmap
    # RbdDevice             Parameters
    #poolname/imagename     id=client,keyring=/etc/ceph/ceph.client.keyring
    ```

  - delete Ceph CLI
    - `kubectl delete -f toolbox.yaml`

- delete ceph cluster:
  - kubectl delete -f cluster.yaml

- teardown
  - > https://rook.io/docs/rook/v1.0/ceph-teardown.html
  - `kubectl delete -f operator.yaml`
  - `kubectl delete -f common.yaml`

- stop minikube
  - `minikube stop`

- [x] TODO: Rook with Ceph on aws

## cluster-update

> https://github.com/rook/rook/blob/master/design/cluster-update.md

- Watch the list of K8s nodes
- If a node is added and useAllNodes: true, trigger an orchestration
- OSDs will be configured on the new node(s)

the problem is whether it can automatically request more resources on aws like EKS?

no, it will not.

## Ceph Block Pool Custom Resource definitions (CRDs)

> https://github.com/rook/rook/blob/master/Documentation/ceph-pool-crd.md

**Erasure Coding**

> Erasure coding allows you to keep your data safe while reducing the storage overhead. Instead of creating multiple replicas of the data, erasure coding divides the original data into chunks of equal size, then generates extra chunks of that same size for redundancy.
>
> For example, if you have an object of size 2MB, the simplest erasure coding with two data chunks would divide the object into two chunks of size 1MB each (data chunks). One more chunk (coding chunk) of size 1MB will be generated. In total, 3MB will be stored in the cluster. The object will be able to suffer the loss of any one of the chunks and still be able to reconstruct the original object.
>
> The number of data and coding chunks you choose will depend on your resiliency to loss and how much storage overhead is acceptable in your storage cluster. Here are some examples to illustrate how the number of chunks affects the storage and loss toleration.
>
| Data chunks (k) | Coding chunks (m) | Total storage | Losses Tolerated | OSDs required |
| --------------- | ----------------- | ------------- | ---------------- | ------------- |
| 2               | 1                 | 1.5x          | 1                | 3             |
| 2               | 2                 | 2x            | 2                | 4             |
| 4               | 2                 | 1.5x          | 2                | 6             |
| 16              | 4                 | 1.25x         | 4                | 20            |
>
> The failureDomain must be also be taken into account when determining the number of chunks. The failure domain determines the level in the Ceph CRUSH hierarchy where the chunks must be uniquely distributed. This decision will impact whether node losses or disk losses are tolerated. There could also be performance differences of placing the data across nodes or osds.
>
> - `host`: All chunks will be placed on unique hosts
> - `osd`: All chunks will be placed on unique OSDs
>
> If you do not have a sufficient number of hosts or OSDs for unique placement the pool can be created, although a PUT to the pool will hang.
> [Ceph crush-map](http://docs.ceph.com/docs/master/rados/operations/crush-map/)
> [Crush algorithm](https://ceph.com/wp-content/uploads/2016/08/weil-crush-sc06.pdf)