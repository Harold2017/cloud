#

## Rook

> [rook](https://github.com/rook/rook)
> [rook on k8s with ceph](https://github.com/rook/rook)
> ![rook with k8s](http://www.yangguanjun.com/images/rook-architecture.png)

Rook with Ceph is at Stable status where others are Alpha or Beta

> deploy ceph cluster with rook
>
> ![architecture](http://www.yangguanjun.com/images/kubernetes.png)
>
> after deploy ceph cluster with rook, it provides Volume Claim to App in k8s
>
> three kinds of Volume Claim services (from Ceph):
>
> - Volume: no extra components
> - FileSystem: deploy with MDS
> - Object: deploy with RGW

## Rook operator

- the component where Rook interact with K8s
- only one inside the whole Rook cluster

## Rook Agent

- interact with Rook operator, execute commands
- run on each node in the cluster as well as Rook operator pod (every k8s node).
- different Agent for different storage systems

## Get_started

> [example yaml](https://github.com/rook/rook/tree/release-1.0/cluster/examples/kubernetes/ceph)

- start minikube
  - `minikube start`
- deploy rook operator
  - `kubectl create -f common.yaml`
  - `kubectl create -f operator.yaml`
  - verify rook-ceph-operator, rook-ceph-agent and rook-discover pods are in `Running` status
    - `kubectl -n rook-ceph get pod`
- create rook ceph cluster
  - change `dataDirHostPath` to `/data/rook` in `cluster.yaml`
  - `kubectl create -f cluster.yaml`
  - `kubectl -n rook-ceph get pod -o wide`

    ```bash
    NAME                                   READY   STATUS      RESTARTS   AGE   IP            NODE       NOMINATED NODE   READINESS GATES
    rook-ceph-agent-2m8pg                  1/1     Running     0          18m   10.0.2.15     minikube   <none>           <none>
    rook-ceph-mgr-a-59c767b6f6-vszwm       1/1     Running     0          14m   172.17.0.10   minikube   <none>           <none>
    rook-ceph-mon-a-76894554fc-ftbp4       1/1     Running     0          15m   172.17.0.7    minikube   <none>           <none>
    rook-ceph-mon-b-7fcb8b77f9-jfnft       1/1     Running     0          15m   172.17.0.8    minikube   <none>           <none>
    rook-ceph-mon-c-75b6987849-7x2t4       1/1     Running     0          14m   172.17.0.9    minikube   <none>           <none>
    rook-ceph-operator-7bbb59d7bd-jsxz6    1/1     Running     0          19m   172.17.0.5    minikube   <none>           <none>
    rook-ceph-osd-prepare-minikube-g2lhj   0/2     Completed   1          14m   172.17.0.11   minikube   <none>           <none>
    rook-discover-2c6gt                    1/1     Running     0          18m   172.17.0.6    minikube   <none>           <none>
    ```

  - `kubectl -n rook-ceph get deployment`

    ```bash
    NAME                 READY   UP-TO-DATE   AVAILABLE   AGE
    rook-ceph-mgr-a      1/1     1            1           16m
    rook-ceph-mon-a      1/1     1            1           17m
    rook-ceph-mon-b      1/1     1            1           17m
    rook-ceph-mon-c      1/1     1            1           16m
    rook-ceph-operator   1/1     1            1           21m
    ```

  - enter in ceph-mon container to see the ceph.conf `docker exec -it b3aa2496c62e bash`
    - `find . -name ceph.conf`
    - `cat ./etc/ceph/ceph.conf`

  - enter in ceph-mgr container to see the ceph.conf `docker exec -it b3aa2496c62e bash`
    - `cat ./etc/ceph/ceph.conf`

  - ceph cluster config is generated by `pkg/daemon/ceph/config/config.go`

- check operator pod log
  - find the pod `kubectl -n rook-ceph get pods -o wide | grep operator`
  - check log `kubectl -n rook-ceph log rook-ceph-operator-7bbb59d7bd-jsxz6 | less`

- check component log
  - `kubectl -n rook-ceph log rook-ceph-mon-a-76894554fc-ftbp4`

- ceph-toolbox:
  - > https://rook.io/docs/rook/v1.0/ceph-toolbox.html
  - deploy: `kubectl create -f toolbox.yaml`
  - check: `kubectl -n rook-ceph get pods -o wide | grep ceph-tools`
  - enter this pod and try Ceph CLI command: `kubectl -n rook-ceph exec -it rook-ceph-tools-7855f6666-8mdnh bash`
  - `ceph status`

    ```bash
    [root@minikube /]# ceph status
    cluster:
        id:     cc5f7923-4566-4c88-81ab-70efe6d5a840
        health: HEALTH_OK

    services:
        mon: 3 daemons, quorum a,b,c (age 83m)
        mgr: a(active, since 82m)
        osd: 0 osds: 0 up, 0 in

    data:
        pools:   0 pools, 0 pgs
        objects: 0 objects, 0 B
        usage:   0 B used, 0 B / 0 B avail
        pgs:
    ```

  - `cat /etc/ceph/ceph.conf`

    ```bash
    [root@minikube /]# cat /etc/ceph/ceph.conf
    [global]
    mon_host = 10.111.151.180:6789,10.98.115.176:6789,10.109.88.55:6789

    [client.admin]
    keyring = /etc/ceph/keyring
    ```

  - `cat /etc/ceph/ceph.conf`

    ```bash
    [root@minikube /]# cat /etc/ceph/rbdmap
    # RbdDevice             Parameters
    #poolname/imagename     id=client,keyring=/etc/ceph/ceph.client.keyring
    ```

  - delete Ceph CLI
    - `kubectl delete -f toolbox.yaml`

- delete ceph cluster:
  - kubectl delete -f cluster.yaml

- teardown
  - > https://rook.io/docs/rook/v1.0/ceph-teardown.html
  - `kubectl delete -f operator.yaml`
  - `kubectl delete -f common.yaml`

- stop minikube
  - `minikube stop`

- [ ] TODO: Rook with Ceph on aws
